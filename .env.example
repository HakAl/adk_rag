# Application Configuration
ENVIRONMENT=development
DEBUG=false

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
CHAT_MODEL=llama3.1:8b-instruct-q4_K_M

# Vector Store Performance Settings
# Number of documents to retrieve per query (lower = faster)
RETRIEVAL_K=3

# ChromaDB HNSW Index Settings (lower values = faster queries, slightly lower accuracy)
CHROMA_HNSW_CONSTRUCTION_EF=100
CHROMA_HNSW_SEARCH_EF=50

# Logging
LOG_LEVEL=INFO
LOG_TO_FILE=false

# Multi-Provider Configuration (optional)
# Leave blank to use only local Ollama provider

# Anthropic Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-haiku-latest

# Google Configuration
GOOGLE_API_KEY=
GOOGLE_MODEL=gemini-2.0-flash